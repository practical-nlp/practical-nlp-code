{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GVXrddQRLrQU"
   },
   "source": [
    "This notebook shows how to use Elastic Search to index and search through data. We will use a dataset called CMU Book summaries [dataset](http://www.cs.cmu.edu/~dbamman/booksummaries.html). Alternateively, the dataset's link can be found in the `BookSummaries_Link.md` file under the Data folder in Ch7. \n",
    "\n",
    "For this code to work, elastic search instance has to be running in the background. \n",
    "For this you need to follow these steps :\n",
    "\n",
    "Docker :\n",
    "   1. Install Docker\n",
    "   2. Create Network : docker network create elastic\n",
    "   3. Pull Image : docker pull docker.elastic.co/elasticsearch/elasticsearch:8.9.1\n",
    "   4. Run Image : docker run --name elasticsearch --net elastic -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -t docker.elastic.co/elasticsearch/elasticsearch:8.9.1\n",
    "   5. After Running the last command the container will give you the username and password to login, the user most likely be named as \"elastic\" and password will be given just beside it.\n",
    "\n",
    "Linux :\n",
    "\n",
    "   1. Go to the elasticsearch-X.Y.Z/bin folder on your machine\n",
    "   2. Run ./elasticsearch.  \n",
    "    \n",
    "Windows :\n",
    "\n",
    "   1.  Download the latest [release](https://www.elastic.co/guide/en/elasticsearch/reference/current/windows.html)\n",
    "   2.  Run .\\bin\\elasticsearch.bat\n",
    "   \n",
    "[ElasticSearch Documentation](https://www.elastic.co/guide/index.html)\n",
    "    \n",
    "You should now be able to access this instance on localhost:9200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "  Obtaining dependency information for elasticsearch from https://files.pythonhosted.org/packages/bb/06/81b1d71ba0567ff39d0f98f3637e810846df92f6733aee46004a194b51ea/elasticsearch-8.9.0-py3-none-any.whl.metadata\n",
      "  Downloading elasticsearch-8.9.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting elastic-transport<9,>=8 (from elasticsearch)\n",
      "  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2,>=1.26.2 in /Users/abhijeetsingh/Documents/DL/Ch2/DL/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.16)\n",
      "Requirement already satisfied: certifi in /Users/abhijeetsingh/Documents/DL/Ch2/DL/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.7.22)\n",
      "Downloading elasticsearch-8.9.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.5/395.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.4.0 elasticsearch-8.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbO4arQuLrQe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch \n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7gy5xXpLrQq"
   },
   "outputs": [],
   "source": [
    "#elastic search instance has to be running on the machine. Default port is 9200. \n",
    "\n",
    "#Call the Elastic Search instance, and delete any pre-existing index\n",
    "es=Elasticsearch([{'host':'localhost','port':9200,'scheme':\"https\"}], http_auth=('elastic', 'yQIpShQvIXJ5gqcImcM9'), verify_certs=False)\n",
    "if es.indices.exists(index=\"myindex\"):\n",
    "    es.indices.delete(index='myindex', ignore=[400, 404]) #Deleting existing index for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riA5ep9yLrQ1",
    "outputId": "78d1be5e-3c28-4342-8d36-754146b357ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n",
      "indexed 100 documents\n"
     ]
    }
   ],
   "source": [
    "#Build an index from booksummaries dataset. I am using only 500 documents for now.\n",
    "path = \"./Data/booksummaries/booksummaries.txt\" #Add your path.\n",
    "count = 1\n",
    "for line in open(path):\n",
    "    fields = line.split(\"\\t\")\n",
    "    doc = {'id' : fields[0],\n",
    "            'title': fields[2],\n",
    "            'author': fields[3],\n",
    "            'summary': fields[6]\n",
    "          }\n",
    "\n",
    "    res = es.index(index=\"myindex\", id=fields[0], body=doc)\n",
    "    count = count+1\n",
    "    if count%100 == 0:\n",
    "        print(\"indexed 100 documents\")\n",
    "    if count == 501:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGZjVbWlLrRB",
    "outputId": "0867238c-15aa-4a01-bbe1-0fce2abc628a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your index has 414 entries\n"
     ]
    }
   ],
   "source": [
    "#Check to see how big is the index\n",
    "res = es.search(index=\"myindex\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Your index has %d entries\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ajt1YhMbLrRI",
    "outputId": "679721a1-a4a6-45e3-8775-33247e5a1a39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your search returned 16 results.\n"
     ]
    }
   ],
   "source": [
    "#Try a test query. The query searches \"summary\" field which contains the text\n",
    "#and does a full text query on that field.\n",
    "res = es.search(index=\"myindex\", body={\"query\": {\"match\": {\"summary\": \"animal\"}}})\n",
    "print(\"Your search returned %d results.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZcEXsQYLrRP",
    "outputId": "794c9038-9bbe-4dc4-dd73-9283ec42c2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dead Air\n",
      " The first person narrative begins on 11 September 2001, and Banks uses the protagonist's conversati\n"
     ]
    }
   ],
   "source": [
    "#Printing the title field and summary field's first 100 characters for 2nd result\n",
    "print(res[\"hits\"][\"hits\"][2][\"_source\"][\"title\"])\n",
    "print(res[\"hits\"][\"hits\"][2][\"_source\"][\"summary\"][:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkYJBQaHLrRW",
    "outputId": "4ecd428d-fc38-4347-9521-df3f400e6ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your search returned 7 results:\n",
      "All's Well That Ends Well\n",
      " Helena, the orphan daughter of a famous physician, is the ward of the Countess of Rousillon, and ho\n",
      "\n",
      "The Last Man\n",
      " Mary Shelley states in the introduction that in 1818 she discovered, in the Sibyl's cave near Naple\n",
      "ng leaves the throne, the monarchy come to an end and a republic is created. When the king dies the Countess attempts to raise their son, Adrian, to reclaim the throne, but Adrian opposes his mother a\n",
      "The Luck of Barry Lyndon\n",
      " Redmond Barry of Bally Barry, born to a genteel but ruined Irish family, fancies himself a gentlema\n",
      "chy, where they win considerable sums of money and Redmond cleverly sets up a plan to marry a young countess of some means. Again, fortune turns against him, and a series of circumstances undermines h\n",
      "Carmilla\n",
      " The story is presented by Le Fanu as part of the casebook of Dr Hesselius, whose departures from me\n",
      "ily heirloom restored portraits arrives at the castle, Laura finds one of her ancestors, \"Mircalla, Countess Karnstein\", dated 1698. The portrait resembles Carmilla exactly, down to the mole on her ne\n",
      "Anna Karenina\n",
      " The novel is divided into eight parts. Its epigraph is Vengeance is mine, I will repay, from Romans\n",
      " at the railway station to meet Anna, Stiva bumps into Vronsky; he is there to meet his mother, the Countess Vronskaya. Anna and Vronskaya have traveled and talked together in the same carriage. As th\n",
      "Murder on the Orient Express\n",
      " Hercule Poirot boards the Orient Express in Constantinople. The train is unusually crowded for the \n",
      "us tragic actress of the New York stage, and was Sonia Armstrong's mother and Daisy's grandmother; *Countess Andrenyi (née Helena Goldenberg) was Sonia Armstrong's sister; *Count Andryeni was the husb\n",
      "War and Peace\n",
      " War and Peace has a large cast of characters, the majority of whom are introduced in the first book\n",
      "is impetuous and eager to join the army when of age. The heads of the family, Count Ilya Rostov and Countess Natalya Rostova, are an affectionate couple but forever worried about their disordered fina\n"
     ]
    }
   ],
   "source": [
    "#match query considers both exact matches, and fuzzy matches and works as a OR query. \n",
    "#match_phrase looks for exact matches.\n",
    "while True:\n",
    "    query = input(\"Enter your search query: \")\n",
    "    if query == \"STOP\":\n",
    "        break\n",
    "    res = es.search(index=\"myindex\", body={\"query\": {\"match_phrase\": {\"summary\": query}}})\n",
    "    print(\"Your search returned %d results:\" % res['hits']['total']['value'])\n",
    "    for hit in res[\"hits\"][\"hits\"]:\n",
    "        print(hit[\"_source\"][\"title\"])\n",
    "        #to get a snippet 100 characters before and after the match\n",
    "        loc = hit[\"_source\"][\"summary\"].lower().index(query)\n",
    "        print(hit[\"_source\"][\"summary\"][:100])\n",
    "        print(hit[\"_source\"][\"summary\"][loc-100:loc+100])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XU7OUNXLLrRd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ElasticSearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
