
# Social Media

Set of notebooks associated with Chapter 8 of the book

1. **[Create a wordcloud](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/01_WordCloud.ipynb)**: How to create a wordcloud. This is often used to get a quick sense of given text corpus at hand.

2. **[Effect of different tokenizers on Social Media Text Data](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/02_DifferentTokenizers.ipynb)** : Here we show how different tokenizers can give different output for the same input text. When dealing to text data from social platforms this can have huge bearing on the performance of the task.  Here, we will be working with 5 different tokenizers, namely:

    * [word_tokenize from NLTK](https://www.nltk.org/api/nltk.tokenize.html)
   * [TweetTokenizer from NLTK](https://www.nltk.org/api/nltk.tokenize.html)
   * [Twikenizer](https://pypi.org/project/twikenizer/)
   * [Twokenizer by ARK@CMU](http://www.cs.cmu.edu/~ark/TweetNLP/)
   * [twokenize](https://github.com/leondz/twokenize)
    

3. **[Trending topics](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/03_TrendingTopics.ipynb)**: Find trending topics on Twitter using tweepy

4. **[Sentiment Analysis](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/04_Textblob.ipynb)**: Basic sentiment analysis using TextBlob 

5. **[Preprocessing Social Media Text Data](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/05_smtd_preprocessing.py)**: Common steps involved in pre-processing pipeline for Social Media Text Data

6. **[Text representation of Social Media Text Data](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/06_SMTD_embeddings.ipynb)**: How to use embeddings to represent Social Media Text Data

8. **Sentiment Analysis**:  Here we use the preprocessing and representation steps learnt before to build a better classifier. 
