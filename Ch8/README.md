
# Social Media

## ğŸ”– Outline

To be added


## ğŸ—’ï¸ Notebooks

Set of notebooks associated with the chapter. 


1. **[Create a wordcloud](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/01_WordCloud.ipynb)**: How to create a word cloud. This is often used to get a quick sense of given text corpus at hand.

2. **[Effect of different tokenizers on Social Media Text Data](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/02_DifferentTokenizers.ipynb)** : Here we show how different tokenizers can give different output for the same input text. When dealing with text data from social platforms this can have a huge bearing on the performance of the task. Â Here, we will be working with 5 different tokenizers, namely:

Â  Â  * [word_tokenize from NLTK](https://www.nltk.org/api/nltk.tokenize.html)
Â  Â  * [TweetTokenizer from NLTK](https://www.nltk.org/api/nltk.tokenize.html)
Â  Â  * [Twikenizer](https://pypi.org/project/twikenizer/)
Â  Â  * [Twokenizer by ARK@CMU](http://www.cs.cmu.edu/~ark/TweetNLP/)
Â  Â  * [twokenize](https://github.com/leondz/twokenize)
Â  Â  

3. **[Trending topics](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/03_TrendingTopics.ipynb)**: Find trending topics on Twitter using tweepy

4. **[Sentiment Analysis](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/04_Sentiment_Analysis_Textblob.ipynb)**: Basic sentiment analysis using TextBlob 

5. **[Preprocessing Social Media Text Data](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/O5_smtd_preprocessing.py)**: Common functions involved in the pre-processing pipeline for Social Media Text Data.

6. **[Text representation of Social Media Text Data](https://github.com/practical-nlp/practical-nlp/blob/master/Ch8/06_SMTD_embeddings.ipynb)**: How to use embeddings to represent Social Media Text Data

7. **Sentiment Analysis**: Â Here we use the preprocessing and representation steps learnt before to build a better classifier.Â 


## ğŸ–¼ï¸ Figures

Color figures as requested by the readers. 

![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-1.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-2.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-3.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-4.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-5.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-6.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-7.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-8.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-9.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-10.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-11.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-12.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-13.png)
![figure](https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/8-14.png)
