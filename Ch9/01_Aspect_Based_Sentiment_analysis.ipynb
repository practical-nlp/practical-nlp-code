{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will deomonstrate aspect based sentiment analysis using [Varder](https://github.com/cjhutto/vaderSentiment) and [Stanford Core NLP](https://stanfordnlp.github.io/CoreNLP/index.html).<br>\n",
    "<br>**VADER Sentiment Analysis**: VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.(source:[github](https://github.com/cjhutto/vaderSentiment))<br>\n",
    "Stanford NLP have a live demo of aspect based sentiment analysis [here](http://nlp.stanford.edu:8080/sentiment/rntnDemo.html).<br><br>\n",
    "**Stanford Core NLP**: \"Most sentiment prediction systems work just by looking at words in isolation, giving positive points for positive words and negative points for negative words and then summing up these points. That way, the order of words is ignored and important information is lost. In constrast, our new deep learning model actually builds up a representation of whole sentences based on the sentence structure. It computes the sentiment based on how words compose the meaning of longer phrases. This way, the model is not as easily fooled as previous models.\"(source: [Stanford Core NLP](https://nlp.stanford.edu/sentiment/index.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install vaderSentiment\n",
    "!pip install pycorenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/samyak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/samyak/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets analyze these three sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = \"This fried chicken tastes very good. It is juicy and perfectly cooked.\"\n",
    "negative = \"This fried chicken tasted bad. It is dry and overcooked.\"\n",
    "ambiguous = \"Except the amazing fried chicken everything else at the restaurant tastes very bad.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VarderSentiment\n",
    "It scores from -1 to 1. -1 being negative and 1 being positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(text):\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "    score = sentiment_analyzer.polarity_scores(text)\n",
    "    pprint(text)\n",
    "    pprint(score)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:\n",
      "'This fried chicken tastes very good. It is juicy and perfectly cooked.'\n",
      "{'compound': 0.8122, 'neg': 0.0, 'neu': 0.575, 'pos': 0.425}\n",
      "------------------------------\n",
      "Negative:\n",
      "'This fried chicken tasted bad. It is dry and overcooked.'\n",
      "{'compound': -0.5423, 'neg': 0.28, 'neu': 0.72, 'pos': 0.0}\n",
      "------------------------------\n",
      "Ambiguous:\n",
      "('Except the amazing fried chicken everything else at the restaurant tastes '\n",
      " 'very bad.')\n",
      "{'compound': 0.0018, 'neg': 0.204, 'neu': 0.592, 'pos': 0.204}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive:\")\n",
    "sentiment_analyzer_scores(positive)\n",
    "\n",
    "print(\"Negative:\")\n",
    "sentiment_analyzer_scores(negative)\n",
    "\n",
    "print(\"Ambiguous:\")\n",
    "sentiment_analyzer_scores(ambiguous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the sentiment analyzer performed well on the positive and negative case. When taking into consideration the ambiguous sentence, it calculated the compound sentiment to be close to 0, i.e, neutral.<br>\n",
    "But it seems to be a negative comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_sentiment(text):\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    \n",
    "    positive_words=[]\n",
    "    neutral_words=[]\n",
    "    negative_words=[]\n",
    "    for word in tokenized_text:\n",
    "        if (sentiment_analyzer.polarity_scores(word)['compound']) >= 0.1:\n",
    "            positive_words.append(word)\n",
    "        elif (sentiment_analyzer.polarity_scores(word)['compound']) <= -0.1:\n",
    "            negative_words.append(word)\n",
    "        else:\n",
    "            neutral_words.append(word)\n",
    "    print(text)\n",
    "    print('Positive:',positive_words)        \n",
    "    print('Negative:',negative_words)    \n",
    "    print('Neutral:',neutral_words)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This fried chicken tastes very good. It is juicy and perfectly cooked.\n",
      "Positive: ['good', 'perfectly']\n",
      "Negative: []\n",
      "Neutral: ['This', 'fried', 'chicken', 'tastes', 'very', '.', 'It', 'is', 'juicy', 'and', 'cooked', '.']\n",
      "------------------------------\n",
      "This fried chicken tasted bad. It is dry and overcooked.\n",
      "Positive: []\n",
      "Negative: ['bad']\n",
      "Neutral: ['This', 'fried', 'chicken', 'tasted', '.', 'It', 'is', 'dry', 'and', 'overcooked', '.']\n",
      "------------------------------\n",
      "Except the amazing fried chicken everything else at the restaurant tastes very bad.\n",
      "Positive: ['amazing']\n",
      "Negative: ['bad']\n",
      "Neutral: ['Except', 'the', 'fried', 'chicken', 'everything', 'else', 'at', 'the', 'restaurant', 'tastes', 'very', '.']\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_word_sentiment(positive)\n",
    "get_word_sentiment(negative)\n",
    "get_word_sentiment(ambiguous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford Core NLP\n",
    "Before moving on to execute the code we need to start the Stanford Core NLP server on our local machine.<br> To do that follow the steps below (tested on debian should work fine for other distributions too):\n",
    "1. Download the Stanford Core NLP model from [here](https://stanfordnlp.github.io/CoreNLP/#download).\n",
    "2. Unizip the folder\n",
    "3. cd into the folder<br>\n",
    "    ```cd stanford-corenlp-4.0.0/```\n",
    "4. Start the server using this command:<br>\n",
    "    ```java -mx5g -cp \"./*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 10000```\n",
    "<br><br>\n",
    "If you do not have java installed on your system please install it from the official [Oracle](https://www.oracle.com/in/java/technologies/javase-downloads.html) page.\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "def get_sentiment(text):\n",
    "    res = nlp.annotate(text,\n",
    "                       properties={'annotators': 'sentiment',\n",
    "                                   'outputFormat': 'json',\n",
    "                                   'timeout': 1000,\n",
    "                       })\n",
    "    print(text)\n",
    "    print('Sentiment:', res['sentences'][0]['sentiment'])\n",
    "    print('Sentiment score:', res['sentences'][0]['sentimentValue'])\n",
    "    print('Sentiment distribution (0-v. negative, 5-v. positive:', res['sentences'][0]['sentimentDistribution'])\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This fried chicken tastes very good. It is juicy and perfectly cooked.\n",
      "Sentiment: Negative\n",
      "Sentiment score: 1\n",
      "Sentiment distribution (0-v. negative, 5-v. positive: [0.14784497645863, 0.42150440150006, 0.26795232397677, 0.14973929036748, 0.01295900769705]\n",
      "------------------------------\n",
      "This fried chicken tasted bad. It is dry and overcooked.\n",
      "Sentiment: Verynegative\n",
      "Sentiment score: 0\n",
      "Sentiment distribution (0-v. negative, 5-v. positive: [0.59929214372637, 0.37183747332338, 0.00491027284258, 0.01321244183821, 0.01074766826945]\n",
      "------------------------------\n",
      "Except the amazing fried chicken everything else at the restaurant tastes very bad.\n",
      "Sentiment: Negative\n",
      "Sentiment score: 1\n",
      "Sentiment distribution (0-v. negative, 5-v. positive: [0.14730433605028, 0.42068997423614, 0.26920777577949, 0.14985314657637, 0.01294476735772]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_sentiment(positive)\n",
    "get_sentiment(negative)\n",
    "get_sentiment(ambiguous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see the model successfully predicts the ambigous sentence which the Varder failed to predict correctly.<br>\n",
    "The code in this notebook has been adapted from this [article](https://towardsdatascience.com/sentiment-analysis-beyond-words-6ca17a6c1b54).",
    "See below code for colab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
